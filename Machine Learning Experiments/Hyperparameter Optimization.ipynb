{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZo1mGpqa-kX"
      },
      "source": [
        "# **Hyperparameter Optimization**\n",
        "\n",
        "In machine learning, hyperparameter optimization or tuning is the goal of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value controls the learning process. By contrast, the values of other parameters (typically node weights) get learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KwdniPYuKxDT",
        "outputId": "d284acd2-3972-41fc-d2f7-50d20ad5d25a"
      },
      "source": [
        "# Import Library.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load Dataset.\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv\"\n",
        ")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0827d81a-ed86-4b3a-aa5c-2b86a7650fdc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0827d81a-ed86-4b3a-aa5c-2b86a7650fdc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0827d81a-ed86-4b3a-aa5c-2b86a7650fdc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0827d81a-ed86-4b3a-aa5c-2b86a7650fdc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWVGBjyeLIcs"
      },
      "source": [
        "# Dataset Summary.\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75UZA3IBVH5O"
      },
      "source": [
        "# **Exploratory Data Analysis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbEiVg2tNugh"
      },
      "source": [
        "sns.pairplot(data, hue=\"Outcome\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tEnLlANN6ao"
      },
      "source": [
        "# Split the dataset into features and target values.\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Feature Scaling.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi3b-q9kO-m6"
      },
      "source": [
        "# **Using Random Forest Classifier.**\n",
        "\n",
        "[**sklearn.ensemble.RandomForestClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
        "\n",
        "\n",
        "The main parameters used by a Random Forest Classifier are:\n",
        "\n",
        "\n",
        "*   **criterion** = the function used to evaluate the quality of a split.\n",
        "*   **max_depth** = maximum number of levels allowed in each tree.\n",
        "*   **max_features** = maximum number of features considered when splitting a node.\n",
        "*   **min_samples_leaf** = minimum number of samples which can be stored in a tree leaf.\n",
        "*   **min_samples_split** = minimum number of samples necessary in a node to cause node splitting.\n",
        "*   **n_estimators** = number of trees in the ensamble."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbj381QbPAcw"
      },
      "source": [
        "# Use Random Forest, with manual Hyperparameter Optimization.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    criterion=\"entropy\",\n",
        "    max_features=\"sqrt\",\n",
        "    min_samples_leaf=10,\n",
        "    random_state=42,\n",
        ")\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the test set results.\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeZiOXbxXU7Z",
        "outputId": "b03481ee-39b9-4398-e2c6-72e4d6b53429"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy Score is \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score is  0.7552083333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.84      0.81       123\n",
            "           1       0.68      0.61      0.64        69\n",
            "\n",
            "    accuracy                           0.76       192\n",
            "   macro avg       0.73      0.72      0.73       192\n",
            "weighted avg       0.75      0.76      0.75       192\n",
            "\n",
            "[[103  20]\n",
            " [ 27  42]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9hB7WCgX2go"
      },
      "source": [
        "# **Grid Search**\n",
        "\n",
        "[**sklearn.model_selection.GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fEru-A1X5l-",
        "outputId": "e4fdf0b6-868e-4ac9-9fb1-4658666c65b8"
      },
      "source": [
        "\"\"\" Hyperparameter Optimization. \"\"\"\n",
        "\n",
        "parameters = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"criterion\": [\"entropy\", \"gini\"],\n",
        "    \"max_depth\": [None, 1, 3, 5],\n",
        "    \"min_samples_split\": [2, 3, 5],\n",
        "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "}\n",
        "\n",
        "print(parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [100, 200, 300], 'criterion': ['entropy', 'gini'], 'max_depth': [None, 1, 3, 5], 'min_samples_split': [2, 3, 5], 'max_features': ['auto', 'sqrt', 'log2'], 'min_samples_leaf': [1, 2, 4]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj_8Ox3UchJQ"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=clf, param_grid=parameters, cv=10, n_jobs=-1, verbose=2\n",
        ")\n",
        "grid_search = grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGPKpfldUuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ead5891-de85-46fe-8e6c-a15443539217"
      },
      "source": [
        "best_grid = grid_search.best_estimator_\n",
        "print(grid_search.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(criterion='entropy', max_features='auto',\n",
            "                       min_samples_leaf=2, min_samples_split=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbXbhKdadcyU"
      },
      "source": [
        "# Predict the test set results.\n",
        "y_pred = best_grid.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCfnFqpoemLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a74fc7a-c867-4a3e-feb2-92c83b2454fc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score 0.7447916666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       123\n",
            "           1       0.64      0.65      0.65        69\n",
            "\n",
            "    accuracy                           0.74       192\n",
            "   macro avg       0.72      0.72      0.72       192\n",
            "weighted avg       0.75      0.74      0.75       192\n",
            "\n",
            "[[98 25]\n",
            " [24 45]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fx4o1aFRp-5"
      },
      "source": [
        "# **Random Search**\n",
        "\n",
        "[**sklearn.model_selection.RandomizedSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hGXGQNxSr60",
        "outputId": "98145086-a257-455d-a02b-6fb1aeca8603"
      },
      "source": [
        "\"\"\" Hyperparameter Optimization. \"\"\"\n",
        "\n",
        "# Number of trees in Random Forest.\n",
        "n_estimators = [int(x) for x in np.linspace(start=100, stop=2000, num=10)]\n",
        "\n",
        "# Number of features to consider at every split.\n",
        "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
        "\n",
        "# Maximum number of levels in the tree.\n",
        "max_depth = [int(x) for x in np.linspace(10, 1000, 10)]\n",
        "\n",
        "# Minimum number of samples required to split a node.\n",
        "min_samples_split = [2, 3, 5, 7, 10, 14]\n",
        "\n",
        "# Minimum number of samples required at each leaf node.\n",
        "min_samples_leaf = [1, 2, 3, 4, 6, 7, 9]\n",
        "\n",
        "# Create the Random Grid.\n",
        "random_grid = {\n",
        "    \"n_estimators\": n_estimators,\n",
        "    \"max_features\": max_features,\n",
        "    \"max_depth\": max_depth,\n",
        "    \"min_samples_split\": min_samples_split,\n",
        "    \"min_samples_leaf\": min_samples_leaf,\n",
        "    \"criterion\": [\"entropy\", \"gini\"],\n",
        "}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 3, 5, 7, 10, 14], 'min_samples_leaf': [1, 2, 3, 4, 6, 7, 9], 'criterion': ['entropy', 'gini']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NluKNkGBWeIH"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=clf,\n",
        "    param_distributions=random_grid,\n",
        "    n_iter=100,\n",
        "    cv=10,\n",
        "    verbose=2,\n",
        "    random_state=100,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "random_search = random_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9yyco_MYOXe",
        "outputId": "609d8fa9-d955-4c51-d213-954f8d281f3c"
      },
      "source": [
        "best_random_grid = random_search.best_estimator_\n",
        "print(random_search.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(criterion='entropy', max_depth=450, min_samples_leaf=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndpwIB1vYhV1"
      },
      "source": [
        "# Predict the test set results.\n",
        "y_pred = best_random_grid.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMTNndY4Ycbt",
        "outputId": "35c0b9e6-d275-4094-8ed8-ace4cf71c9ab"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score 0.75\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.81       123\n",
            "           1       0.66      0.64      0.65        69\n",
            "\n",
            "    accuracy                           0.75       192\n",
            "   macro avg       0.73      0.73      0.73       192\n",
            "weighted avg       0.75      0.75      0.75       192\n",
            "\n",
            "[[100  23]\n",
            " [ 25  44]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZnJplLQ0WDe"
      },
      "source": [
        "# **TPOT - Automated Machine Learning for Supervised Classification Tasks**\n",
        "\n",
        "> [**TPOTClassifier**](http://epistasislab.github.io/tpot/api/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wom04b2A3Wa6"
      },
      "source": [
        "!pip install tpot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiRmzWlS1f6S",
        "outputId": "bf7f0abd-5600-405d-fe6c-d99da8db9c8d"
      },
      "source": [
        "\"\"\" Hyperparameter Optimization. \"\"\"\n",
        "\n",
        "# Number of trees in Random Forest.\n",
        "n_estimators = [int(x) for x in np.linspace(start=100, stop=2000, num=10)]\n",
        "\n",
        "# Number of features to consider at every split.\n",
        "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
        "\n",
        "# Maximum number of levels in the tree.\n",
        "max_depth = [int(x) for x in np.linspace(10, 1000, 10)]\n",
        "\n",
        "# Minimum number of samples required to split a node.\n",
        "min_samples_split = [2, 3, 5, 7, 10, 14]\n",
        "\n",
        "# Minimum number of samples required at each leaf node.\n",
        "min_samples_leaf = [1, 2, 3, 4, 6, 7, 9]\n",
        "\n",
        "# Create the Random Grid.\n",
        "random_grid = {\n",
        "    \"n_estimators\": n_estimators,\n",
        "    \"max_features\": max_features,\n",
        "    \"max_depth\": max_depth,\n",
        "    \"min_samples_split\": min_samples_split,\n",
        "    \"min_samples_leaf\": min_samples_leaf,\n",
        "    \"criterion\": [\"entropy\", \"gini\"],\n",
        "}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 3, 5, 7, 10, 14], 'min_samples_leaf': [1, 2, 3, 4, 6, 7, 9], 'criterion': ['entropy', 'gini']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ5uifXn2RM9"
      },
      "source": [
        "from tpot import TPOTClassifier\n",
        "\n",
        "tpot_classifier = TPOTClassifier(\n",
        "    generations=5,\n",
        "    population_size=24,\n",
        "    offspring_size=12,\n",
        "    verbosity=2,\n",
        "    early_stop=10,\n",
        "    config_dict={\"sklearn.ensemble.RandomForestClassifier\": random_grid},\n",
        "    cv=10,\n",
        "    scoring=\"accuracy\",\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "accuracy = tpot_classifier.score(X_test, y_test)\n",
        "print(\"Accuracy is\", accuracy)  # Accuracy is 0.7604166666666666"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixdw1D_cFk25"
      },
      "source": [
        "# **Optimize hyperparameters of the Model using Optuna**\n",
        "\n",
        "> [**Optuna: Automate Hyperparameter Tuning**](https://optuna.org/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tW3HudgGBJ2"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNATIu4THXX5"
      },
      "source": [
        "The hyperparameters of the above algorithm are `n_estimators` and `max_depth` for which we can try different values to see if the model accuracy can be improved. The objective function is modified to accept a trial object. This trial has several methods for sampling hyperparameters. We create a study to run the hyperparameter optimization and finally read the best hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx5r_m--GL1u"
      },
      "source": [
        "import optuna\n",
        "import sklearn.svm\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    classifier = trial.suggest_categorical(\"classifier\", [\"RandomForest\", \"SVC\"])\n",
        "    if classifier == \"RandomForest\":\n",
        "        n_estimators = trial.suggest_int(\"n_estimators\", 200, 2000, 10)\n",
        "        max_depth = int(trial.suggest_float(\"max_depth\", 10, 100, log=True))\n",
        "        clf = sklearn.ensemble.RandomForestClassifier(\n",
        "            n_estimators=n_estimators, max_depth=max_depth\n",
        "        )\n",
        "    else:\n",
        "        c = trial.suggest_float(\"svc_c\", 1e-10, 1e10, log=True)\n",
        "        clf = sklearn.svm.SVC(C=c, gamma=\"auto\")\n",
        "    return sklearn.model_selection.cross_val_score(\n",
        "        clf, X_train, y_train, n_jobs=-1, cv=10\n",
        "    ).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxGp812rHbU2"
      },
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"Accuracy: {}\".format(trial.value))\n",
        "print(\"Best Hyperparameters: {}\".format(trial.params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7A4DDugH06N",
        "outputId": "de3dfc88-cf18-4500-85a0-39510f78c733"
      },
      "source": [
        "print(trial)\n",
        "print(study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenTrial(number=85, state=TrialState.COMPLETE, values=[0.7793708408953417], datetime_start=datetime.datetime(2023, 5, 30, 17, 32, 54, 314049), datetime_complete=datetime.datetime(2023, 5, 30, 17, 33, 27, 643803), params={'classifier': 'RandomForest', 'n_estimators': 1680, 'max_depth': 16.132944824273615}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'classifier': CategoricalDistribution(choices=('RandomForest', 'SVC')), 'n_estimators': IntDistribution(high=2000, log=False, low=200, step=10), 'max_depth': FloatDistribution(high=100.0, log=True, low=10.0, step=None)}, trial_id=85, value=None)\n",
            "{'classifier': 'RandomForest', 'n_estimators': 1680, 'max_depth': 16.132944824273615}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lime Model Interpretation**"
      ],
      "metadata": {
        "id": "uYCi9P6Y7kA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "Uatn18lg8imX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r3TjkEW6zrg"
      },
      "outputs": [],
      "source": [
        "# Import Library.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lime\n",
        "from lime import lime_tabular\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load Dataset.\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv\"\n",
        ")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features and the target variables.\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Split the dataset into the Training set and Test set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply Random Forest Classification Model.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "cwUc44KZ8An8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpretor = lime_tabular.LimeTabularExplainer(\n",
        "    training_data=np.array(X_train),\n",
        "    feature_names=X_train.columns,\n",
        "    mode=\"classification\",\n",
        ")"
      ],
      "metadata": {
        "id": "Mren6YYm8hoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = interpretor.explain_instance(\n",
        "    data_row=X_test.iloc[10], predict_fn=clf.predict_proba\n",
        ")\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "4fqBIhGq8scN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}